{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_rigid_reg_3d.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ajoshiusc/deepReg/blob/master/deep_rigid_reg_3d.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "iLIITh68GSmr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2c4256bd-423f-4618-a77c-c90c24192396"
      },
      "cell_type": "code",
      "source": [
        "#AUM\n",
        "#Shree Ganeshaya Namaha\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "from skimage import transform as tf\n",
        "from skimage.transform import resize, rotate\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "from keras.layers import Input,Conv3D,concatenate,MaxPooling3D,Flatten,Dense,Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from numpy.random import uniform\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.viewer import ImageViewer\n",
        "import cv2\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
            "  warn('Viewer requires Qt')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "F3ZQ3QFWFUku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "\n",
        "from keras import losses\n",
        "sizeX = 128\n",
        "sizeY = 128\n",
        "sizeZ = 128\n",
        "\n",
        "#taken from: https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation\n",
        "# Function to distort image\n",
        "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
        "    \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
        "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
        "         Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
        "         Proc. of the International Conference on Document Analysis and\n",
        "         Recognition, 2003.\n",
        "\n",
        "     Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
        "    \"\"\"\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    shape = image.shape\n",
        "    shape_size = shape[:3]\n",
        "    \n",
        "    # Random affine\n",
        "    center_square = np.float32(shape_size) // 2\n",
        "    square_size = min(shape_size) // 3\n",
        "    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size, center_square[2]-square_size], center_square - square_size])\n",
        "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "#    M = cv2.getAffineTransform(pts1, pts2)\n",
        "#    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dz = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "\n",
        "    x, y, z = np.ndgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
        "    indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1)), np.reshape(z+dz, (-1, 1))\n",
        "\n",
        "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
        "\n",
        "\n",
        "\n",
        "def get_rr_net():\n",
        "    inputs = Input((sizeX, sizeY, sizeZ, 2))\n",
        "    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv2)\n",
        "    poo12 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
        "    \n",
        "    conv4_1 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv4_1)\n",
        "    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(conv5)\n",
        "    flat1 = Flatten()(conv5)\n",
        "    d1= Dense(512,activation='relu')(flat1)\n",
        "    d2= Dense(64,activation='relu')(d1)\n",
        "\n",
        "    out_theta = Dense(3)(d2)\n",
        "#    conv_tx = Conv2D(1, (1, 1), activation=final_activation)(conv5)\n",
        "#    conv_ty = Conv2D(1, (1, 1), activation=final_activation)(conv5)\n",
        "#    conv_theta = Conv2D(1, (1, 1), activation='tanh')(conv5)\n",
        "\n",
        "#    out_img = rotate(inputs,conv_theta)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=out_theta)\n",
        "\n",
        "    model.compile(optimizer='adam', loss=losses.mean_squared_error, metrics=['mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def gen_train_data(img, N=1024,  nodist=0):\n",
        "    imgs_train = np.zeros((N, img.shape[0], img.shape[1], img.shape[2], 2))\n",
        "    noise = 0*uniform(low=-1,high=1,size=imgs_train.shape)\n",
        "    out_train = np.zeros((N, 3))\n",
        "    rot = uniform(low=-60, high=60, size=(N,1))\n",
        "    tx = uniform(low=-100, high=100, size=(N,1))\n",
        "    ty = uniform(low=-100, high=100, size=(N,1))\n",
        "    tz = uniform(low=-100, high=100, size=(N,1))\n",
        "    out_train[:,0]=rot1.squeeze()\n",
        "    out_train[:,1]=rot2.squeeze()\n",
        "    out_train[:,2]=tx.squeeze()\n",
        "    out_train[:,3]=ty.squeeze()\n",
        "    out_train[:,4]=tz.squeeze()\n",
        "\n",
        "\n",
        "    in_rot1 = uniform(low=-60, high=60, size=(N,1))\n",
        "    in_rot2 = uniform(low=-60, high=60, size=(N,1))\n",
        "\n",
        "    for j in range(N):\n",
        "      \n",
        "#        img2 = tf.warp(img,aff)\n",
        "        img2 = sp.ndimage.rotate(img, in_rot[j],mode='edge')\n",
        "        img2 -= np.mean(img2)\n",
        "        img2 /= np.std(img2)\n",
        "        if nodist==0:\n",
        "            img2 = elastic_transform(img2, img2.shape[1] * 1.2, img2.shape[1] * 0.08,img2.shape[1] * 0.08)\n",
        "        \n",
        "        imgs_train[j, :, :, 0] = img2 + (1.0-nodist)*noise[j,:,:,0]\n",
        "       \n",
        "        aff = tf.AffineTransform(rotation = (np.pi/180.0)*np.float(rot[j]), translation=(tx[j],ty[j]))\n",
        "\n",
        "        #img3 = 10-1*np.tanh(img2) + 0*  noise[j,:,:,1]#\n",
        "        img3 = 10-1*np.tanh(tf.warp(img2, aff, mode='edge')) +  (1.0-nodist)*noise[j,:,:,1]#\n",
        "        \n",
        "        if nodist == 0:\n",
        "            img3 = elastic_transform(img3, img3.shape[1] * .2, img3.shape[1] * 0.08,img3.shape[1] * 0.08)\n",
        "\n",
        "        img3 -= np.mean(img3)\n",
        "        img3 /= np.std(img3)\n",
        "        imgs_train[j, :, :, 1] = img3\n",
        "        \n",
        "        if 0:\n",
        "            plt.imshow(img3)\n",
        "            plt.show()\n",
        "            \n",
        "            plt.imshow(img2)\n",
        "            plt.show()\n",
        "             \n",
        "    return imgs_train, out_train\n",
        "\n",
        "\n",
        "def train_model():\n",
        "    print('-'*30)\n",
        "    print('Loading and preprocessing train data...')\n",
        "    print('-'*30)\n",
        "    img = resize(rgb2gray(imread('sample_brain.png')).astype('float32'),(img_rows,img_cols),mode='constant')\n",
        "    mean = np.mean(img)  # mean for data centering\n",
        "    std = np.std(img)  # std for data normalization\n",
        "\n",
        "    img -= mean\n",
        "    img /= std\n",
        "    \n",
        "\n",
        "    print('Creating and compiling model...')\n",
        "    rrmodel = get_rr_net()\n",
        "    rrmodel.load_weights('weights.h5')\n",
        "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    print('Fitting Model')\n",
        "    for repind in range(100):\n",
        "        imgs_train, out_train = gen_train_data(img, 512)\n",
        "        history = rrmodel.fit(imgs_train, out_train, batch_size=64, epochs=5, verbose=1,\n",
        "                              shuffle=True, validation_split=0.2,\n",
        "                              callbacks=[model_checkpoint])\n",
        "\n",
        "    # list all data in history\n",
        "    print(history.history.keys())\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['mean_squared_error'])\n",
        "    plt.plot(history.history['val_mean_squared_error'])\n",
        "    plt.title('model fit mse')\n",
        "    plt.ylabel('mse')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def test_model():\n",
        "    \n",
        "    print('Test data...')\n",
        "    img = resize(rgb2gray(imread('sample_brain.png')).astype('float32'),(img_rows,img_cols),mode='reflect')\n",
        "    mean = np.mean(img)  # mean for data centering\n",
        "    std = np.std(img)  # std for data normalization\n",
        "\n",
        "    img -= mean\n",
        "    img /= std\n",
        "\n",
        "    rrmodel = get_rr_net()\n",
        "    rrmodel.load_weights('weights.h5')\n",
        "\n",
        "    imgs_test, out_test = gen_train_data(img, 4, nodist=1)\n",
        "#    plt.imshow(np.absolute(imgs_test[0,:,:,0].squeeze()),cmap='gray')\n",
        "#    plt.imshow(np.absolute(imgs_test[0,:,:,1].squeeze()),cmap='gray')\n",
        "\n",
        "    pred_theta = rrmodel.predict(imgs_test, verbose=1)\n",
        "\n",
        "    for jj in range(4):\n",
        "        fig=plt.figure(figsize=(20,10)); \n",
        "        fig.add_subplot(1,3,1);ax = plt.gca(); ax.grid(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(np.absolute(imgs_test[jj,:,:,0].squeeze()),cmap='gray')\n",
        "        fig.add_subplot(1,3,2);ax = plt.gca(); ax.grid(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(np.absolute(imgs_test[jj,:,:,1].squeeze()),cmap='gray')\n",
        "        aff = tf.AffineTransform(rotation = (np.pi/180.0)*pred_theta[jj,0], translation=(pred_theta[jj,1],pred_theta[jj,2]))\n",
        "        img2 = tf.warp(np.absolute(imgs_test[jj,:,:,0].squeeze()),aff)\n",
        "        fig.add_subplot(1,3,3);ax = plt.gca(); ax.grid(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img2,cmap='gray')\n",
        "        plt.show()\n",
        "    \n",
        "    \n",
        "    print(pred_theta)\n",
        "    print(out_test)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model()\n",
        "    test_model()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}